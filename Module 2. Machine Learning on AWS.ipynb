{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#AWS-Machine-Learning-Stack\" data-toc-modified-id=\"AWS-Machine-Learning-Stack-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>AWS Machine Learning Stack</a></span></li><li><span><a href=\"#Amazon-Rekognition\" data-toc-modified-id=\"Amazon-Rekognition-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Amazon Rekognition</a></span></li><li><span><a href=\"#Amazon-SageMaker\" data-toc-modified-id=\"Amazon-SageMaker-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Amazon SageMaker</a></span></li><li><span><a href=\"#AWS-Deep-Learning-AMIs\" data-toc-modified-id=\"AWS-Deep-Learning-AMIs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>AWS Deep Learning AMIs</a></span></li><li><span><a href=\"#AWS-Deep-Learning-Containers\" data-toc-modified-id=\"AWS-Deep-Learning-Containers-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>AWS Deep Learning Containers</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Quiz\" data-toc-modified-id=\"Quiz-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Quiz</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Concepts\n",
    "- Analyze which AWS service is most appropriate for your task\n",
    "- Use AWS hosted services such as Rekognition\n",
    "- Understand the SageMaker pipeline from model building to tuning and deployment\n",
    "- Understand the differences between the Deep Learning AMI and Deep Learning containers\n",
    "- Setup infrastructure on AWS for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Machine Learning Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/module2/aws-ml-stack.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. AI Services: using pre-trained models to apply ML on applications. No need for algorithm understanding.\n",
    "    - Rekognition: identify objects, scenes, activities in image and videos\n",
    "    - Polly: text-to-speech voices\n",
    "    - Transcribe: speech-to-text on audio\n",
    "    - Translate: language translations\n",
    "    - Comprehend: find insights and relationships in text, classify document, determine sentiment\n",
    "    - Lex: conversational interface (chatbot), ex. Amazon Alexa\n",
    "    - Forecast: time series forecasting\n",
    "    - Personalize: individualized recommendations from activity stream from customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge Check**\n",
    "\n",
    "Which AWS service is appropriate for understanding the contents of an image?\n",
    "- [ ] Rekognition\n",
    "- [ ] Comprehend\n",
    "- [ ] Transcribe\n",
    "- [ ] Lex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ML Services: hands-on Machine Learning workflow. Managed by Amazon SageMaker that enable data scientist work from end-to-end.\n",
    "    - Ground Truth: labeling process by active learning\n",
    "    - Notebooks: spin up Jupyter server\n",
    "    - Algorithms: use built-in Computer Vision, Natural Language Processing, and Time Series algorithm\n",
    "    - Training: create model from selected algorithm\n",
    "    - Model Tuner: automatically find best settings for algorithm\n",
    "    - Neo: optimize the speed and memory consumption of model\n",
    "    - Endpoints: deployment, host model and generate real-time prediction via HTTP request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge Check**\n",
    "\n",
    "Which Amazon SageMaker components are appropriate for model optimization?\n",
    "- [ ] Ground Truth\n",
    "- [ ] Neo\n",
    "- [ ] Model Tuner\n",
    "- [ ] Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ML Frameworks & Infrastructure: get full control of machine learning workflow.\n",
    "    - Framework:\n",
    "        - Deep Learning: TensorFlow, MxNet, PyTorch, Chainer\n",
    "        - Non-Deep Learning: Scikit-learn and Spark ML\n",
    "    - Infrastructure:\n",
    "        - Amazon Elastic Compute Cloud (EC2) from compute-optimized C5 to GPU-accelerated P3\n",
    "        - Field-Programmable Gate Array (FPGAs)\n",
    "        - Deep Learning Amazon Machine Image (DLAMI): setting up framework and optimized library\n",
    "        - Amazon Elastic Container Service: deep learning containers\n",
    "        - AWS IoT Greengrass: edge deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Rekognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **simple API** for image and video (**Computer Vision**) analysis that is **continuously learning** and **integrated** with other AWS Services (directly with S3 and Lambda)\n",
    "\n",
    "Use case example:\n",
    "- Object, scene, and activity detection\n",
    "- Face-based user verification stystem\n",
    "- Facial analysis: estimate emotion, age, glasses, etc\n",
    "- Identify celebrities in a image/video\n",
    "- Pathing: capture path taken by people in the scene\n",
    "- Identify inapproriate content and the label\n",
    "- Detect and recognize text from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate how to use Amazon Rekognition:\n",
    "\n",
    "1. Register for free account here: https://aws.amazon.com/free\n",
    "2. Click create a free account and fill out the registration form. You will get 12 months of AWS free tier access as a first-time user. You will be ask to input Credit/Debit card and charged $1, but the fee will be returned after several days.\n",
    "3. Once you finish, visit AWS Management Console:\n",
    "\n",
    "<img src=\"assets/module2/aws-management-console.png\" width=\"500\">\n",
    "\n",
    "4. Search for \"Amazon Rekognition\"\n",
    "\n",
    "<img src=\"assets/module2/amazon-rekognition.png\" width=\"500\">\n",
    "\n",
    "5. Visit Demo:\n",
    "    - Object and scene detection: results, request, response\n",
    "    - Video analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/module2/amazon-sagemaker.png\" width=\"500\">\n",
    "\n",
    "1. Ground Truth\n",
    "\n",
    "Help to label the unlabeled dataset of images by active learning. At start, small proportion of images is labeled by human labelers. When the model is confident enough, the prediction will be treated as the label. \n",
    "\n",
    "<img src=\"assets/module2/ground-truth.png\" width=\"500\">\n",
    "\n",
    "2. Notebooks\n",
    "\n",
    "Fully managed Jupyter server to explore datasets and develop ML models. Come with optimized deep and machine learning packages. Built-in algorithm includes:\n",
    "\n",
    "- BlazingText: Natural language processing\n",
    "- DeepAR: Time series forecasting\n",
    "- Factorization Machines: Recommender systems\n",
    "- Image classification\n",
    "- IP Insights\n",
    "- K-Means\n",
    "- K-Nearest Neighbors\n",
    "- Latent Dirichlet Allocation (LDA)\n",
    "- Linear Learner\n",
    "- Neural Topic Model (NTM)\n",
    "- Object2Vec\n",
    "- Object Detection\n",
    "- Principal Component Analysis (PCA)\n",
    "- Random Cut Forest (RCF)\n",
    "- Semantic Segmentation\n",
    "- Sequence-to-Sequence\n",
    "- XGBoost\n",
    "\n",
    "Model training jobs: dedicated to training, downloading dataset, and running models in a containerized environment. Amazon Sagemaker benefits:\n",
    "- Easy to scale up\n",
    "- Save model in Amazon S3\n",
    "- Search and track trained models\n",
    "- Log metrics and console to Amazon CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge Check**\n",
    "\n",
    "What is the recommended approach for model exception debugging?\n",
    "- [ ] Use a SageMaker Notebook to train and debug locally.\n",
    "- [ ] Use a SageMaker Training Job to train on managed infrastructure.\n",
    "\n",
    "What is the recommended approach for model architecture experimentation?\n",
    "\n",
    "- [ ] Use a SageMaker Notebook to train and debug locally.\n",
    "- [ ] Use a SageMaker Training Job to train on managed infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model Tuning: search combination of hyper parameters to result the best model by Bayesian Search instead of Random Search. Estimating the uncertainty for learning rate by accuracy:\n",
    "\n",
    "<img src=\"assets/module2/bayesian-search.png\" width=\"500\">\n",
    "\n",
    "4. Compilation (optional): optimize model (2x faster, 10x less memory). Available hardware platform: Intel, Nvidia, Arm, Qualcomm.\n",
    "\n",
    "5. Deployment option:\n",
    "    - Amazon SageMaker Endpoints: host model with single click to generate predictions in real-time via HTTP request.\n",
    "    - Amazon Elastic Inference: attach low cost GPU to endpoints.\n",
    "    - AWS IoT Greengrass: connected devices can generate prediction even without internet connection.\n",
    "    - Amazon SageMaker Batch Transform: request in a batch dataset instead of single request.\n",
    "    \n",
    "Amazon SageMaker Python SDK: import SageMaker to control the whole workflow from the notebook.\n",
    "\n",
    "<img src=\"assets/module2/python-sdk.png\" width=\"400\">\n",
    "\n",
    "Steps:\n",
    "1. Create an estimator, defines model and training environment.\n",
    "2. `.fit()` to start the training job \n",
    "3. `.deploy()` for deployment\n",
    "4. `.predict()` to generate prediction from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge Check**\n",
    "\n",
    "Using the SageMaker Python SDK, what is the typical estimator/predictor flow?\n",
    "- [ ] Create -> Fit -> Deploy -> Predict -> Delete\n",
    "- [ ] Create -> Predict -> Fit -> Deploy -> Delete\n",
    "- [ ] Create -> Deploy -> Predict -> Fit -> Delete\n",
    "- [ ] Create -> Fit -> Delete -> Deploy -> Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate how to use Amazon SageMaker:\n",
    "\n",
    "1. Search for \"Amazon SageMaker\" in AWS Management Console\n",
    "2. Click Notebook Instances on the left menu bar\n",
    "3. Click Create notebook instance button\n",
    "\n",
    "<img src=\"assets/module2/amazon-sagemaker-notebook-instances.png\" width=\"400\">\n",
    "\n",
    "4. Fill out the form as follows:\n",
    "\n",
    "    * Notebook instance settings\n",
    "        - Notebook instance name: use unique notebook name.\n",
    "        - Notebook instance type: different instance families have different storage and computation capabilities. For deep learning, consider GPU instance such as T3 instance.\n",
    "        - Elastic inference: attach GPU to endpoints.\n",
    "        - Lifecycle configuration: to setup environment.\n",
    "        - Volume size: memory storage for data\n",
    "\n",
    "    * Permissions and encryption\n",
    "        - IAM role: control resources that the notebook allow to acces from S3 buckets. Click create a new role to add the name of S3 to be granted.\n",
    "        - Root access: enable or disable\n",
    "        - Encryption key\n",
    "\n",
    "    * Network: Enable access via VPC (Virtual Private Cloud) or not\n",
    "\n",
    "    * Git repositories: connect to Git\n",
    "\n",
    "    * Tags: keep track of instances\n",
    "\n",
    "5. Wait until the notebook status from Pending to InService\n",
    "6. Congratulations! The notebook is ready to use using Jupyter or JupyterLab\n",
    "7. Open up new Jupyter Notebook using `conda_mxnet_p36` environment\n",
    "8. Try the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 4. 9.]\n",
       "<NDArray 3 @cpu(0)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "a = mx.nd.array([1, 2, 3])\n",
    "a.square()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: don't forget to stop the notebook to prevent additional charge. Delete the notebook if you don't intend to use it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Deep Learning AMIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Machine Image is a template which used to create an instance with Amazon Elastic Compute Cloud (EC2) for cloud computing. It includes the operating system (OS) and pre-installed software dependencies.\n",
    "\n",
    "Amazon EC2:\n",
    "- elastic: increase and decrease capacity of an instance in the cloud\n",
    "- completely controlled: manage via API or AWS management consolue\n",
    "- flexible: select different instance type based on needs\n",
    "- web-scale of computational resources\n",
    "- reliable and secure\n",
    "- inexpensive: pay only for the capacity you use\n",
    "- easy to get started \n",
    "\n",
    "Example of instances:\n",
    "- C4 for computational and input-output task\n",
    "- P3 and G3 NVIDIA GPU for deep learning\n",
    "\n",
    "Two variants of DLAMI:\n",
    "1. Conda DLAMI:\n",
    "    - OS: Ubuntu, Amazon Linux, Windows\n",
    "    - Framework: MXNet, Tensorflow, PyTorch in separate environments\n",
    "2. Base DLAMI:\n",
    "    - OS: Ubuntu, Amazon Linux\n",
    "    - GPU drivers and NVIDIA CUDA libraries (no deep learning framework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge Check**\n",
    "\n",
    "Which Ubuntu AMI is recommended for regular Apache MXNet users?\n",
    "- [ ] Ubuntu 18.04 from Ubuntu\n",
    "- [ ] Ubuntu 18.04 Deep Learning AMI from Amazon Web Services\n",
    "- [ ] Ubuntu 18.04 Deep Learning Base AMI from Amazon Web Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate how to use AWS DLAMI:\n",
    "\n",
    "1. Search for \"EC2\" in the AWS Management Console\n",
    "2. Click Launch instance button\n",
    "3. Search your AMI via AWS Marketplace on the left menu bar. For example, let's search \"Deep Learning Ubuntu\" and click start\n",
    "\n",
    "<img src=\"assets/module2/dlami-marketplace.png\" width=\"400\">\n",
    "\n",
    "4. You will be prompted the price list, click continue to proceed.\n",
    "\n",
    "<img src=\"assets/module2/dlami-price.png\" width=\"400\">\n",
    "\n",
    "5. For deep learning, choose a `p3.2xlarge` instance (or larger) and click Review and Launch button.\n",
    "\n",
    "<img src=\"assets/module2/dlami-instance.png\" width=\"400\">\n",
    "\n",
    "6. Review the configuration, click Launch if you are set.\n",
    "\n",
    "7. You will be prompted to use encryption.\n",
    "    - Choose \"Create a new key pair\"\n",
    "    - Enter key pair name\n",
    "    - Click \"Download Key Pair\", make sure to save the file securely\n",
    "    - Click Launch to start the instance\n",
    "    \n",
    "<img src=\"assets/module2/dlami-key-pair.png\" width=\"400\">\n",
    "    \n",
    "8. Your instance has been created, but you have to connect your instance with the device. Click Action menu, choose Connect and follow the instructions.\n",
    "\n",
    "<img src=\"assets/module2/dlami-connect.png\" width=\"400\">\n",
    "\n",
    "9. Now you can use the pre-installed environment on your local Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Deep Learning Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A container is a standardized unit of software developed by Docker, used to package applications (container image) for development, shipment, and deployment.\n",
    "- Using container, enables OS-level virtualization which enables portability. \n",
    "- Container images created by combining and modifying standard images from container repositories (such as Amazon Elastic Container Registry or ECR).\n",
    "- Amazon ECR:\n",
    "    - is a fully managed Docker container registry by AWS.\n",
    "    - store Docker container images in the cloud.\n",
    "    - used to manage and deploy Docker containers to Amazon Elastic Container Service (ECS).\n",
    "- Amazon ECS:\n",
    "    - support Docker containers to easily run and scale containerized applications on AWS.\n",
    "    - highly scalable\n",
    "    - using simple and secure API calls\n",
    "    - optimized for cost\n",
    "    - high performance service\n",
    "    - used by AWS Fargate, deploy and manage containers without servers\n",
    "- Docker images are pre-installed with deep learning frameworks (MXNet and TensorFlow, others are coming soon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge Check**\n",
    "\n",
    "What are Deep Learning Containers?\n",
    "- [ ] Compressed folders\n",
    "- [ ] Docker Images\n",
    "- [ ] Docker Registries\n",
    "- [ ] VirtualBox Virtual Machines\n",
    "- [ ] Amazon Machine Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment option for Deep Learning Containers:\n",
    "\n",
    "<img src=\"assets/module2/containers-deployment.png\" width=\"400\">\n",
    "\n",
    "Let's demonstrate how to use AWS DLC:\n",
    "\n",
    "1. Search for \"IAM\" in the AWS Management Console\n",
    "2. Select Users on the left menu bar and click \"Add User\" button\n",
    "\n",
    "<img src=\"assets/module2/iam-users.png\" width=\"600\">\n",
    "\n",
    "3. Fill out the \"Set user details\" form\n",
    "    - Fill User name\n",
    "    - Enable Programmatic access\n",
    "    - Click Next: Permission button\n",
    "    \n",
    "<img src=\"assets/module2/iam-set-user-details.png\" width=\"600\">\n",
    "\n",
    "4. Select \"Attach existing policies directly\" and search for \"AmazonEC2ContainerRegistryFullAccess\"\n",
    "\n",
    "<img src=\"assets/module2/iam-set-permissions.png\" width=\"600\">\n",
    "\n",
    "5. Skip tags and jump to Review, Click \"Create user\" button to proceed\n",
    "\n",
    "6. Download .csv credential and return to EC2 instance\n",
    "\n",
    "<img src=\"assets/module2/iam-download-credential.png\" width=\"600\">\n",
    "\n",
    "7. From command line, configure the AWS by `aws configure`\n",
    "8. Login to the registry (provided in the notes) and you should see Login Succeeded\n",
    "\n",
    "<img src=\"assets/module2/command-configure.png\" width=\"600\">\n",
    "\n",
    "9. Run the MXNet training container from Docker\n",
    "\n",
    "<img src=\"assets/module2/command-run-docker.png\" width=\"600\">\n",
    "\n",
    "10. Test if the container can be run or not:\n",
    "\n",
    "<img src=\"assets/module2/command-test-container.png\" width=\"600\">\n",
    "\n",
    "Note: terminate your instance to avoid additional charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Stack, split into three levels:\n",
    "- AI Services: simple and high-level API, using Amazon Rekognition to gain insights for Computer Vision problem.\n",
    "- ML Services: composed of Amazon SageMaker to build, train, and deploy model (end-to-end process)\n",
    "- ML Frameworks & Infrastructure: low-level for deep learning framework by AMIs and containers\n",
    "    - Amazon EC2 instances pre-installed with deep leanring frameworks like MXNet, TensorFlow, and PyTorch.\n",
    "    - Deep Learning containers are Docker container images for MXNet and TensorFlow.\n",
    "    \n",
    "In summary, AWS provides a variety of services and frameworks to give the choice and flexibility to use the services based on needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What data types are supported by Amazon Recognition? Select all that apply.\n",
    "    - [ ] Images\n",
    "    - [ ] Video\n",
    "    - [ ] Audio\n",
    "    - [ ] Text\n",
    "\n",
    "2. What is the recommended strategy for hyper parameter optimisation in Amazon SageMaker?\n",
    "    - [ ] Grid Search\n",
    "    - [ ] Random Search\n",
    "    - [ ] Bayesian Search\n",
    "    - [ ] Binary Tree Search\n",
    "\n",
    "3. Which frameworks come pre-installed on the Deep Learning AMI? Select all that apply.\n",
    "    - [ ] Apache MXNet\n",
    "    - [ ] Chainer\n",
    "    - [ ] PyTorch\n",
    "    - [ ] TensorFlow\n",
    "\n",
    "4. Where are Amazon Deep Learning Containers made available?\n",
    "    - [ ] Amazon Machine Image Marketplace\n",
    "    - [ ] Amazon Elastic Container Registry\n",
    "    - [ ] Amazon SageMaker built-in algorithms\n",
    "    - [ ] Amazon EC2 Service Console\n",
    "\n",
    "5. What’s the recommended tool for optimising models for edge deployment?\n",
    "    - [ ] Amazon Personalize\n",
    "    - [ ] Amazon SageMaker Automatic Model Tuner\n",
    "    - [ ] Amazon SageMaker Neo\n",
    "    - [ ] AWS Auto Scaling\n",
    "\n",
    "6. Assume you have 10,000 unlabelled images of foods, and need to train an object detection model for edge deployment in a smart fridge. Using Amazon SageMaker, in what order would you use the following components?\n",
    "    - [ ] Ground Truth -> Automatic Model Tuner -> Neo\n",
    "    - [ ] Neo -> Automatic Model Tuner -> Ground Truth\n",
    "    - [ ] Automatic Model Tuner -> Ground Truth -> Neo\n",
    "    - [ ] Ground Truth -> Neo -> Automatic Model Tuner\n",
    "\n",
    "7. What learning procedure does SageMaker Ground Truth use to label data?\n",
    "    - [ ] Active Learning\n",
    "    - [ ] Unsupervised Learning\n",
    "    - [ ] Metric Learning\n",
    "    - [ ] Human Learning\n",
    "\n",
    "8. Which Amazon SageMaker built-in algorithms can be used for understanding images?\n",
    "    - [ ] BlazingText\n",
    "    - [ ] DeepAR\n",
    "    - [ ] Object Detection\n",
    "    - [ ] Semantic Segmentation\n",
    "\n",
    "9. Which AWS service let’s you attach low-cost GPU-powered acceleration to Amazon EC2 and Amazon SageMaker instances?\n",
    "    - [ ] AWS IoT Greengrass\n",
    "    - [ ] Amazon SageMaker Batch Transform\n",
    "    - [ ] AWS Auto Scaling\n",
    "    - [ ] Amazon Elastic Inference\n",
    "    \n",
    "10. You need to start an Amazon SageMaker Notebook instance to use Amazon Rekognition?\n",
    "    - [ ] True\n",
    "    - [ ] False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "computer-vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
